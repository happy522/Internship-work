{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find filler word from any audio",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHGinYNxlMen"
      },
      "source": [
        "#This code will find the filler word from audio\n",
        "#Inputs: audio files with .wav format\n",
        "#Output: time when filler word occurs\n",
        "#Files this notebook refers: Excel sheet 'https://docs.google.com/spreadsheets/d/15JyW9TBGHSUhA4c3NOao0V6eYOikZ8x4/edit#gid=1805822620'\n",
        "#Author: Khushi Pitroda\n",
        "#Date: 19-July-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcAZw7tRlNO5"
      },
      "source": [
        "#Prerequisite\n",
        "#.Wav (audio) files\n",
        "#parselmouth\n",
        "#data from excel for predefined values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD3HmTVplNW5",
        "outputId": "682e7eaf-a1ca-4654-d503-93457192adb9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a04f5gRelNZv"
      },
      "source": [
        "#Change directory \n",
        "#Go to shared with me folder create shortcut of shared folder and add it to the my drive so you can access that shared folder from here.\n",
        "\n",
        "import os \n",
        "os.chdir(\"/content/drive/MyDrive/Paleru_Khushi\")    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHo8Qw8lSnH",
        "outputId": "2a60707f-2063-44e0-a170-0191653d49a5"
      },
      "source": [
        "pip install praat-parselmouth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from praat-parselmouth) (1.19.5)\n",
            "Installing collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsDCEkYHlU2y"
      },
      "source": [
        "import json  \n",
        "import parselmouth\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc_am2_Lkoit",
        "outputId": "e226a0c2-125d-4ea3-a968-0d01e72cc328"
      },
      "source": [
        "#Before running this code, make sure the JSON file asrOutput.json is placed in the folder in the drive\n",
        "#Make sure you have uploaded the audio file in AWS and dowloaded the JSON file in advance.\n",
        "#Produces the transcript of the audio file\n",
        "\n",
        "from operator import itemgetter           #for mapping\n",
        "import math\n",
        "#provide location of json file of audio here\n",
        "json_file = \"/content/drive/MyDrive/Paleru_Khushi/JSON/asrOutput1.json\"\n",
        "\n",
        "#provide location of audio file here\n",
        "sound_file = \"/content/drive/My Drive/Paleru_Khushi/Filler_words_audios/Person_um1.wav\"\n",
        "  \n",
        "f = open(json_file)           #create json file by uploading audio files (https://aws.amazon.com/getting-started/hands-on/create-audio-transcript-transcribe/)\n",
        "\n",
        "data = json.load(f)\n",
        "#print(data)\n",
        "#dictonary containing all information \n",
        "x = data['results'] ['items']         #fetch result(keyname) from data and from result(sub-dictonary) fetch transcripts stores in list named x  \n",
        "words_dict = {}\n",
        "for i in range(1,len(x)):             #for getting each single word, start_time and start_time from the list\n",
        "  time = []\n",
        "  start_time = 0                      #initial value\n",
        "  end_time = 0                        #initial value\n",
        "\n",
        "  word = x[i]['alternatives'][0]['content']         #get the word- content from dictonary inside the list inside the dicrtonary named alternatives which is inside the list x. print(x) for more understanding.\n",
        "  confidence = x[i]['alternatives'][0]['confidence'] \n",
        "  if word!='.' and word!=',' and word!='?':                       #punctuation doesn't have timestamps so ignoring it\n",
        "    start_time = x[i][\"start_time\"]                 #from list getting value of start_time for each word- content\n",
        "    end_time = x[i]['end_time']                     #from list getting value of end_time for each word- content\n",
        "    list = [word,start_time,end_time,confidence]\n",
        "    words_dict[start_time] = list\n",
        "    #print(word)\n",
        "    \n",
        "start_point_aws = 0\n",
        "end_point_aws = 0\n",
        "start_point_algo = 0\n",
        "end_point_algo = 0\n",
        "#print(words_dict)       \n",
        "def false_positive(start_point_algo, end_point_algo):\n",
        "  flag = 1\n",
        "  global start_point_aws, end_point_aws\n",
        "\n",
        "  start_point_aws_prev =  start_point_aws\n",
        "  end_point_aws_prev = end_point_aws\n",
        "  diffrence_aws_prev = end_point_aws - start_point_aws\n",
        "\n",
        "  start_point_algo_prev = start_point_algo\n",
        "  end_point_algo_prev = end_point_algo\n",
        "  diffrence_algo_prev = end_point_algo - start_point_algo\n",
        "\n",
        "  diffrence_prev = diffrence_aws_prev - diffrence_algo_prev\n",
        "\n",
        "  for key in words_dict:\n",
        "    start_point_aws = float(words_dict[key][1])\n",
        "    end_point_aws = float(words_dict[key][2])\n",
        "    confidence = float(words_dict[key][3])\n",
        "    word_aws = words_dict[key][0]\n",
        "\n",
        "    diffrence_aws = end_point_aws - start_point_aws\n",
        "    diffrence_algo = end_point_algo - start_point_algo\n",
        "\n",
        "    diffrence = diffrence_aws - diffrence_algo\n",
        "    #applying filters to remove false positives by comparing it with AWS transcript\n",
        "    if start_point_algo < end_point_aws and end_point_algo < end_point_aws and end_point_algo > start_point_aws:\n",
        "      #if word is detected from transcript\n",
        "      if word_aws == \"um\" or word_aws ==\"uh\": \n",
        "        print(f\"--------------------------FILLER WORD DETECTED:---------------------\\nWord: {word_aws} start_point_aws: {start_point_aws}, end_point_aws: {end_point_aws} Duration : {end_point_aws-start_point_aws}, Actual_duration: {end_point_algo-start_point_algo}, confidence:{confidence}\")        #printing all the values\n",
        "        flag = 0\n",
        "      elif start_point_aws == start_point_aws_prev:\n",
        "        #repetition  filter\n",
        "        if diffrence_algo_prev > diffrence_algo:\n",
        "          print(f\"FALSE POSITIVE WORD DETECTED:\\nWord: {word_aws} start_point_aws: {start_point_aws} end_point_aws: {end_point_aws} Duration : {end_point_aws-start_point_aws}, Actual_duration: {end_point_algo-start_point_algo}, confidence:{confidence}\")        #printing all the values\n",
        "          flag = 0\n",
        "        else:\n",
        "          print(f\"FILLER WORD:\\nWord: {word_aws} start_point_aws: {start_point_aws} end_point_aws: {end_point_aws}Duration : {end_point_aws-start_point_aws}, Actual_duration: {end_point_algo-start_point_algo}, confidence:{confidence}\")        #printing all the values\n",
        "        start_point_aws_prev = start_point_aws\n",
        "        flag = 0\n",
        "      #if it's false positive\n",
        "      else:\n",
        "        print(f\"FALSE POSITIVE WORD DETECTED:\\nWord: {word_aws} start_point_aws: {start_point_aws} end_point_aws: {end_point_aws} Duration : {end_point_aws-start_point_aws}, Actual_duration: {end_point_algo-start_point_algo}, confidence:{confidence}\")        #printing all the values\n",
        "        start_point_aws_prev = start_point_aws\n",
        "        end_point_aws_prev = start_point_aws\n",
        "        start_point_algo_prev = start_point_algo\n",
        "        end_point_algo_prev = end_point_algo\n",
        "        flag = 0\n",
        "      break\n",
        "    #if nothing is in transcript\n",
        "    elif start_point_algo < end_point_aws and end_point_algo > start_point_aws:\n",
        "      print(f\"Maybe a filler word: \\nstart_point_algo {start_point_algo}, end_point_algo {end_point_algo}, Duration : {end_point_aws-start_point_aws}, confidence:{confidence}\")   \n",
        "      flag = 0\n",
        "  if flag == 1:\n",
        "    print(\"Maybe a filler word:\")  \n",
        "  print(f\"start_point_algo {start_point_algo}, end_point_algo {end_point_algo}\\n\\n\")\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "snd = parselmouth.Sound(sound_file) #for importing audio file with filler words\n",
        "pitch = snd.to_pitch()                 #finding pitch of that filler word\n",
        "\n",
        "times = pitch.ts()                    #for getting values of different time stamps according to pitch values\n",
        "hop_dur = .01   #predefined value for time step\n",
        "num_form = 4    #predefined value for max number of formants = the number of peaks with which the entire spectrum is modelled\n",
        "max_form_freq = 4500    #predefined value for maximum formant\n",
        "\n",
        "form = snd.to_formant_burg(time_step=hop_dur, max_number_of_formants=num_form, maximum_formant = max_form_freq, pre_emphasis_from=50.0)   #for getting formant values\n",
        "\n",
        "form_1_vals = []  #list for storing audio's f1\n",
        "form_2_vals = []  #list for storing audio's f2\n",
        "form_3_vals = []  #list for storing audio's f3\n",
        "form_4_vals = []  #list for storing audio's f4\n",
        "\n",
        "\n",
        "#values from data in 'https://docs.google.com/spreadsheets/d/15JyW9TBGHSUhA4c3NOao0V6eYOikZ8x4/edit#gid=1805822620'\n",
        "\n",
        "#for f1\n",
        "max_formant_f1 = 785       #Average Maximum value from audios (between range of Start_F1 and End_F1) based on excel sheet\n",
        "min_formant_f1 = 545       #Average Minimum value from audios (between range of Start_F1 and End_F1) based on excel sheet\n",
        "Max_Consecutive_Positive_Dev_f1 = 60     #Maximum difference between two consecutive formants. (Deviation)\n",
        "Max_Consecutive_Negative_Dev_f1 = -66    #Minimum difference between two consecutive formants. (Deviation)\n",
        "min_no_of_continuous_value_f1 = 13\n",
        "formant_f1 = 0\n",
        "i=1\n",
        "arr_f1 = []      #for storing the values of formants \n",
        "temp_f1 = []\n",
        "j=0\n",
        "\n",
        "#for f2\n",
        "max_formant_f2 = 2390.201396       #Average Maximum value from audios (between range of Start_F2 and End_F2) based on excel sheet\n",
        "min_formant_f2 = 1027.659305       #Average Minimum value from audios (between range of Start_F2 and End_F2) based on excel sheet\n",
        "Max_Consecutive_Positive_Dev_f2 = 116.86   #Maximum difference between two consecutive formants. (Deviation)\n",
        "Max_Consecutive_Negative_Dev_f2 = -152.86    #Minimum difference between two consecutive formants. (Deviation)\n",
        "min_no_of_continuous_value_f2 = 13\n",
        "formant_f2 = 0\n",
        "arr_f2 = []      #for storing the values of formants \n",
        "temp_f2 = []\n",
        "\n",
        "for dt in times:      #for loop used with average of time instants\n",
        "\n",
        "    form_1_vals.append(form.get_value_at_time(1,dt))    #storing the values of f2 audio in list\n",
        "    prev_formant_f1 = formant_f1      #storing formant in prev_formant variable for next iteration\n",
        "    formant_f1 = form.get_value_at_time(1,dt)    #getting formant value at perticular time\n",
        "    Dev_f1 = formant_f1-prev_formant_f1    #getting deviation from 2 formant-prev_formant (2 consecutive points)\n",
        "\n",
        "    \n",
        "    form_2_vals.append(form.get_value_at_time(2,dt))    #storing the values of f2 audio in list\n",
        "    prev_formant_f2 = formant_f2      #storing formant in prev_formant variable for next iteration\n",
        "    formant_f2 = form.get_value_at_time(2,dt)    #getting formant value at perticular time\n",
        "    Dev_f2 = formant_f2-prev_formant_f2    #getting deviation from 2 formant-prev_formant (2 consecutive points)\n",
        "\n",
        "    if str(formant_f1) != 'nan' and str(prev_formant_f1) != 'nan'  and str(formant_f2) != 'nan' and str(prev_formant_f2) != 'nan' :    #if both formats are not null\n",
        "    #checking for conditions based on data, if formant is less than maximum formant acquired from excel, if formant is greater  than minimum formant, if deviation is between minimum and maximum  consecutive deviation then it'll go inside.\n",
        "      # f1 and f2 filters\n",
        "      if formant_f1 <max_formant_f1 and formant_f1 > min_formant_f1 and Dev_f1 < Max_Consecutive_Positive_Dev_f1 and Dev_f1>Max_Consecutive_Negative_Dev_f1 and formant_f2 <max_formant_f2 and formant_f2 > min_formant_f2 and Dev_f2<Max_Consecutive_Positive_Dev_f2 and Dev_f2>Max_Consecutive_Negative_Dev_f2:   \n",
        "        arr_f2.append(dt)   #if all conditions are satisfied then it'll store that time in arr \n",
        "        i=i+1            #increment of i (i is for consecutive points)\n",
        "      else:           #if all 4 conditions are not fulfilled then i will be zero and array will be empty \n",
        "        j=i\n",
        "        temp_f2 = arr_f2\n",
        "        i=0\n",
        "        arr_f2 = []\n",
        "    if j > min_no_of_continuous_value_f2:\n",
        "      #print(\"f2\")\n",
        "      start_point_algo = 0\n",
        "      end_point_algo = 0\n",
        "      start_point_algo = temp_f2[0]\n",
        "      end_point_algo = temp_f2[len(temp_f2)-1]\n",
        "      \n",
        "      j=0\n",
        "      false_positive(start_point_algo,end_point_algo)\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: and start_point_aws: 6.32 end_point_aws: 7.12 Duration : 0.7999999999999998, Actual_duration: 0.16999999999999993, confidence:1.0\n",
            "start_point_algo 6.37326530612245, end_point_algo 6.54326530612245\n",
            "\n",
            "\n",
            "FILLER WORD:\n",
            "Word: and start_point_aws: 6.32 end_point_aws: 7.12Duration : 0.7999999999999998, Actual_duration: 0.21999999999999975, confidence:1.0\n",
            "start_point_algo 6.8532653061224496, end_point_algo 7.073265306122449\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: are start_point_aws: 7.13 end_point_aws: 7.37 Duration : 0.2400000000000002, Actual_duration: 0.1299999999999999, confidence:0.566\n",
            "start_point_algo 7.17326530612245, end_point_algo 7.30326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: and start_point_aws: 10.87 end_point_aws: 11.14 Duration : 0.27000000000000135, Actual_duration: 0.129999999999999, confidence:1.0\n",
            "start_point_algo 10.913265306122451, end_point_algo 11.04326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: success start_point_aws: 11.64 end_point_aws: 12.34 Duration : 0.6999999999999993, Actual_duration: 0.16999999999999993, confidence:1.0\n",
            "start_point_algo 11.93326530612245, end_point_algo 12.10326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: and start_point_aws: 12.35 end_point_aws: 12.93 Duration : 0.5800000000000001, Actual_duration: 0.17999999999999972, confidence:1.0\n",
            "start_point_algo 12.473265306122451, end_point_algo 12.653265306122451\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: our start_point_aws: 12.94 end_point_aws: 13.72 Duration : 0.7800000000000011, Actual_duration: 0.34000000000000163, confidence:1.0\n",
            "start_point_algo 12.96326530612245, end_point_algo 13.303265306122452\n",
            "\n",
            "\n",
            "FILLER WORD:\n",
            "Word: our start_point_aws: 12.94 end_point_aws: 13.72Duration : 0.7800000000000011, Actual_duration: 0.16000000000000014, confidence:1.0\n",
            "start_point_algo 13.323265306122451, end_point_algo 13.483265306122451\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: lives start_point_aws: 14.79 end_point_aws: 15.15 Duration : 0.3600000000000012, Actual_duration: 0.16000000000000014, confidence:1.0\n",
            "start_point_algo 14.893265306122451, end_point_algo 15.053265306122452\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: And start_point_aws: 17.31 end_point_aws: 17.96 Duration : 0.6500000000000021, Actual_duration: 0.2699999999999996, confidence:1.0\n",
            "start_point_algo 17.423265306122453, end_point_algo 17.693265306122452\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: the start_point_aws: 17.97 end_point_aws: 18.48 Duration : 0.5100000000000016, Actual_duration: 0.3099999999999987, confidence:1.0\n",
            "start_point_algo 18.033265306122452, end_point_algo 18.34326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: behind start_point_aws: 19.37 end_point_aws: 19.83 Duration : 0.4599999999999973, Actual_duration: 0.14000000000000057, confidence:1.0\n",
            "start_point_algo 19.58326530612245, end_point_algo 19.72326530612245\n",
            "\n",
            "\n",
            "--------------------------FILLER WORD DETECTED:---------------------\n",
            "Word: um start_point_aws: 20.29, end_point_aws: 20.83 Duration : 0.5399999999999991, Actual_duration: 0.379999999999999, confidence:0.949\n",
            "start_point_algo 20.36326530612245, end_point_algo 20.74326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: that's start_point_aws: 24.45 end_point_aws: 25.08 Duration : 0.629999999999999, Actual_duration: 0.38000000000000256, confidence:0.936\n",
            "start_point_algo 24.47326530612245, end_point_algo 24.853265306122452\n",
            "\n",
            "\n",
            "Maybe a filler word: \n",
            "start_point_algo 26.38326530612245, end_point_algo 26.65326530612245, Duration : 1.1099999999999994, confidence:1.0\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: in start_point_aws: 26.55 end_point_aws: 26.83 Duration : 0.2799999999999976, Actual_duration: 0.2699999999999996, confidence:1.0\n",
            "start_point_algo 26.38326530612245, end_point_algo 26.65326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: that start_point_aws: 27.2 end_point_aws: 28.14 Duration : 0.9400000000000013, Actual_duration: 0.21000000000000085, confidence:1.0\n",
            "start_point_algo 27.29326530612245, end_point_algo 27.50326530612245\n",
            "\n",
            "\n",
            "FILLER WORD:\n",
            "Word: that start_point_aws: 27.2 end_point_aws: 28.14Duration : 0.9400000000000013, Actual_duration: 0.21000000000000085, confidence:1.0\n",
            "start_point_algo 27.75326530612245, end_point_algo 27.96326530612245\n",
            "\n",
            "\n",
            "FALSE POSITIVE WORD DETECTED:\n",
            "Word: understood start_point_aws: 29.44 end_point_aws: 30.34 Duration : 0.8999999999999986, Actual_duration: 0.2699999999999996, confidence:1.0\n",
            "start_point_algo 29.59326530612245, end_point_algo 29.86326530612245\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}